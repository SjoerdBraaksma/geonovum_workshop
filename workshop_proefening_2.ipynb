{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643da097",
   "metadata": {},
   "source": [
    "# Proefening 2\n",
    "\n",
    "In deze tweede oefening gaan we een complexere analyse doen, door te kijken welke punten overlappen met een deel van de BGT vlakken.\n",
    "Run hiervoor eerst het notebook download_bgt.ipynb. Hier kan je eerst de beschikbare collecties van de BGT printen, en vervolgens een deel van de BGT downloaden.\n",
    "Deze wordt automatisch in je output folder opgeslagen.\n",
    "\n",
    "het script maakt gebruik van de bounding box uit de env.yml file. De bounding box is in het format [minx, miny, maxx, maxx]. Uit je AHN5 file kan je de minimale waardes al halen. Tel hier 1000 bij op (want het is 1km bij 1km) voor de max waardes. Pas deze waarde voor nu niet aan, omdat die overeenkomt met je data.\n",
    "\n",
    "In de env.yml staan deze al goed, als je geen eigen .las file hebt gekozen!\n",
    "\n",
    "De output wordt opgeslagen in je output folder, als bgt_collections.gpkg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8119be8b",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e195cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy as lp\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.strtree import STRtree\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c9ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load environment variables\n",
    "def load_yaml(path_to_yaml: str):\n",
    "    \"\"\"\n",
    "    Load yaml file\n",
    "    \"\"\"\n",
    "    with open(path_to_yaml, \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "env = load_yaml(\"env.yml\")\n",
    "data_folder = env[\"data_folder\"]\n",
    "output_folder = Path(data_folder) / \"output\"\n",
    "bbox = env[\"bbox\"]\n",
    "bgt_name = env[\"bgt_name\"]\n",
    "subset = env[\"subset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c97bdb",
   "metadata": {},
   "source": [
    "### Handige functies\n",
    "\n",
    "Onderstaande functies helpen ons in deze workshop. Bij elke functie zie je een korte beschrijving van wat hij doet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5acb2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(directory: str):\n",
    "    \"\"\"\n",
    "    Get all files with a specific extension in a directory.\n",
    "    \"\"\"\n",
    "\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".las\")]\n",
    "    return files\n",
    "\n",
    "\n",
    "def lasdata_loader(filepaths: str | list, single_array: bool = True):\n",
    "    \"\"\"\n",
    "    Load one or multiple .las or .laz files.\n",
    "    Can return the data as a single numpy array (if single_array=True)\n",
    "    or as a list of numpy arrays (if single_array=False).\n",
    "    \"\"\"\n",
    "    if isinstance(filepaths, str):\n",
    "        filepaths = [filepaths]\n",
    "\n",
    "    all_points = []\n",
    "    for filepath in filepaths:\n",
    "        las = lp.read(filepath)\n",
    "        coords = np.vstack((las.points.x, las.points.y, las.points.z))\n",
    "        point_cloud = coords.transpose()\n",
    "        all_points.append(point_cloud)\n",
    "\n",
    "    if single_array:\n",
    "        all_points = np.concatenate(all_points)\n",
    "\n",
    "    return all_points\n",
    "\n",
    "\n",
    "def to_las(\n",
    "    points: np.ndarray, colors: Optional[np.ndarray], extra_dim: Optional[dict]\n",
    ") -> lp.LasData:\n",
    "    \"\"\"\n",
    "    Converts data to laspy format.\n",
    "    Laspy RGB channels must be of 16-bit format 0-65535.\n",
    "    These default for the Pointcloud class is 0-255.\n",
    "    \"\"\"\n",
    "    header = lp.LasHeader(point_format=3, version=\"1.2\")\n",
    "\n",
    "    las = lp.LasData(header)\n",
    "    las.x = points[:, 0]\n",
    "    las.y = points[:, 1]\n",
    "    las.z = points[:, 2]\n",
    "\n",
    "    if colors is not None:\n",
    "        point_colors = colors.astype(np.uint16)\n",
    "        if points.shape[0] != point_colors.shape[0]:\n",
    "            error = ValueError(\"Points and color length are not equal.\")\n",
    "            logging.error(error)\n",
    "            raise error\n",
    "\n",
    "        las.red = point_colors[:, 0]\n",
    "        las.green = point_colors[:, 1]\n",
    "        las.blue = point_colors[:, 2]\n",
    "\n",
    "    if extra_dim is not None:\n",
    "        if not isinstance(extra_dim, dict):\n",
    "            error = ValueError(\n",
    "                \"extra_dim should be a dictionary with the dimname as key, and the value a N1 array or list of values\"\n",
    "            )\n",
    "            logging.error(error)\n",
    "            raise error\n",
    "\n",
    "        for key, value in extra_dim.items():\n",
    "            if points.shape[0] != value.shape[0]:\n",
    "                logging.info(\"Points and extra dimension length are not equal.\")\n",
    "                error = ValueError(\"Points and extra dimension length are not equal.\")\n",
    "                logging.error(error)\n",
    "                raise error\n",
    "\n",
    "            if key != \"classification\":\n",
    "                las.add_extra_dim(lp.ExtraBytesParams(name=key, type=\"uint32\"))\n",
    "                setattr(las, key, value)\n",
    "            else:\n",
    "                las.classification = value\n",
    "\n",
    "    return las"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3508df7",
   "metadata": {},
   "source": [
    "### Stap 1: De las data laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbfb8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/utrecht_subset\"  # Pad naar de folder met de las/laz files\n",
    "output_folder = Path(data_folder) / \"output\"  # Pad naar de folder voor output\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db337ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/utrecht_subset/AHN5_C_125000_456000_7_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_7.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_1_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_3.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_4.las', 'data/utrecht_subset/AHN5_C_125000_456000_0_5.las', 'data/utrecht_subset/AHN5_C_125000_456000_3_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_8_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_1.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_6.las', 'data/utrecht_subset/AHN5_C_125000_456000_9_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_5_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_6_0.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_8.las', 'data/utrecht_subset/AHN5_C_125000_456000_4_2.las', 'data/utrecht_subset/AHN5_C_125000_456000_7_9.las', 'data/utrecht_subset/AHN5_C_125000_456000_2_6.las']\n",
      "Loaded data/utrecht_subset/AHN5_C_125000_456000_3_3.las\n"
     ]
    }
   ],
   "source": [
    "lasfiles = get_files_in_directory(data_folder)\n",
    "print(lasfiles)\n",
    "\n",
    "lasfile_path = [\n",
    "    filepath\n",
    "    for filepath in lasfiles\n",
    "    if filepath\n",
    "    == f\"data/utrecht_subset/AHN5_C_{int(bbox[0])}_{int(bbox[1])}_{subset[0]}_{subset[0]}.las\"\n",
    "][0]\n",
    "\n",
    "lasdata = lasdata_loader(lasfile_path, single_array=True)\n",
    "print(f\"Loaded {lasfile_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4047e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geodata_with_index(filepath: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load each layer of the geodata as separate GeoDataFrames.\n",
    "    Returns a dictionary with layer names as keys and GeoDataFrames as values.\n",
    "    \"\"\"\n",
    "\n",
    "    layers = gpd.list_layers(filepath).name.to_list()\n",
    "    geodata = {}\n",
    "    for layer in layers:\n",
    "        geodata[layer] = gpd.read_file(filepath, layer=layer)\n",
    "\n",
    "    return geodata\n",
    "\n",
    "\n",
    "geodata_dict = load_geodata_with_index(Path(data_folder) / bgt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f55c7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beschikbare lagen in de BGT data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>begroeidterreindeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>onbegroeidterreindeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ondersteunendwaterdeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ondersteunendwegdeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openbareruimte</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pand</td>\n",
       "      <td>MultiPolygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vegetatieobject_punt</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vegetatieobject_vlak</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waterdeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wegdeel</td>\n",
       "      <td>Polygon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name geometry_type\n",
       "0     begroeidterreindeel       Polygon\n",
       "1   onbegroeidterreindeel       Polygon\n",
       "2  ondersteunendwaterdeel       Polygon\n",
       "3    ondersteunendwegdeel       Polygon\n",
       "4          openbareruimte  MultiPolygon\n",
       "5                    pand  MultiPolygon\n",
       "6    vegetatieobject_punt         Point\n",
       "7    vegetatieobject_vlak       Polygon\n",
       "8               waterdeel       Polygon\n",
       "9                 wegdeel       Polygon"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zie welke layers er beschikbaar zijn in de BGT data\n",
    "print(\"Beschikbare lagen in de BGT data:\")\n",
    "gpd.list_layers(Path(data_folder) / bgt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad ook de geodata, kies hier een layer die je interessant lijkt!\n",
    "layer = \"pand\"\n",
    "geodata = gpd.read_file(Path(data_folder) / bgt_name, layer=layer)\n",
    "geodata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5f736",
   "metadata": {},
   "source": [
    "### Stap 2: De bounding box van de lasdata vergelijken met de BGT data\n",
    "\n",
    "In de volgende stap maken we twee bounding boxes: 1 om de punten in de lasdata heen, en een om de BGT data.\n",
    "Deze zouden moeten overlappen, gezien de BGT een voorbereide subset is op de volledige pointcloud tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cad27be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benodigde functies\n",
    "def pointcloud_to_bbox_gdf(points: np.ndarray, crs: str = \"EPSG:28992\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Create a bounding box polygon from a point cloud and return as single-row GeoDataFrame.\n",
    "\n",
    "    Args:\n",
    "        points: numpy array with shape (n_points, 2) or (n_points, 3) - X,Y coordinates (Z ignored if present)\n",
    "        crs: Coordinate reference system for the output GeoDataFrame\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame with single row containing bounding box polygon and metadata\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract X,Y coordinates (ignore Z if present)\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # Calculate bounding box\n",
    "    min_x, min_y = np.min(xy_points, axis=0)\n",
    "    max_x, max_y = np.max(xy_points, axis=0)\n",
    "\n",
    "    # Create bounding box polygon\n",
    "    bbox_polygon = box(min_x, min_y, max_x, max_y)\n",
    "\n",
    "    # Create GeoDataFrame with metadata\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"geometry\": [bbox_polygon],\n",
    "            \"min_x\": [min_x],\n",
    "            \"min_y\": [min_y],\n",
    "            \"max_x\": [max_x],\n",
    "            \"max_y\": [max_y],\n",
    "            \"width\": [max_x - min_x],\n",
    "            \"height\": [max_y - min_y],\n",
    "            \"area\": [bbox_polygon.area],\n",
    "            \"n_points\": [len(points)],\n",
    "        },\n",
    "        crs=crs,\n",
    "    )\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def pointcloud_to_bbox_coords(points: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Get bounding box coordinates from point cloud in [min_x, min_y, max_x, max_y] format.\n",
    "\n",
    "    Args:\n",
    "        points: numpy array with point coordinates\n",
    "\n",
    "    Returns:\n",
    "        List with [min_x, min_y, max_x, max_y]\n",
    "    \"\"\"\n",
    "    xy_points = points[:, :2]\n",
    "    min_x, min_y = np.min(xy_points, axis=0)\n",
    "    max_x, max_y = np.max(xy_points, axis=0)\n",
    "\n",
    "    return [min_x, min_y, max_x, max_y]\n",
    "\n",
    "\n",
    "def compare_bboxes(points: np.ndarray, geodata: gpd.GeoDataFrame, crs: str = \"EPSG:28992\") -> tuple:\n",
    "    \"\"\"\n",
    "    Compare bounding boxes of point cloud and geodata.\n",
    "\n",
    "    Args:\n",
    "        points: numpy array with point coordinates\n",
    "        geodata: GeoDataFrame to compare with\n",
    "        crs: coordinate reference system\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (pointcloud_bbox_gdf, geodata_bbox_gdf, combined_bbox_gdf)\n",
    "    \"\"\"\n",
    "    # Get point cloud bounding box\n",
    "    pc_bbox = pointcloud_to_bbox_gdf(points, crs)\n",
    "\n",
    "    # Get geodata bounding box\n",
    "    geo_bounds = geodata.total_bounds  # [min_x, min_y, max_x, max_y]\n",
    "    geo_bbox_polygon = box(geo_bounds[0], geo_bounds[1], geo_bounds[2], geo_bounds[3])\n",
    "\n",
    "    geo_bbox = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"geometry\": [geo_bbox_polygon],\n",
    "            \"min_x\": [geo_bounds[0]],\n",
    "            \"min_y\": [geo_bounds[1]],\n",
    "            \"max_x\": [geo_bounds[2]],\n",
    "            \"max_y\": [geo_bounds[3]],\n",
    "            \"width\": [geo_bounds[2] - geo_bounds[0]],\n",
    "            \"height\": [geo_bounds[3] - geo_bounds[1]],\n",
    "            \"area\": [geo_bbox_polygon.area],\n",
    "            \"n_features\": [len(geodata)],\n",
    "        },\n",
    "        crs=geodata.crs,\n",
    "    )\n",
    "\n",
    "    # Combined bounding box\n",
    "    combined_min_x = min(pc_bbox.iloc[0][\"min_x\"], geo_bbox.iloc[0][\"min_x\"])\n",
    "    combined_min_y = min(pc_bbox.iloc[0][\"min_y\"], geo_bbox.iloc[0][\"min_y\"])\n",
    "    combined_max_x = max(pc_bbox.iloc[0][\"max_x\"], geo_bbox.iloc[0][\"max_x\"])\n",
    "    combined_max_y = max(pc_bbox.iloc[0][\"max_y\"], geo_bbox.iloc[0][\"max_y\"])\n",
    "\n",
    "    combined_polygon = box(combined_min_x, combined_min_y, combined_max_x, combined_max_y)\n",
    "    combined_bbox = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"geometry\": [combined_polygon],\n",
    "            \"min_x\": [combined_min_x],\n",
    "            \"min_y\": [combined_min_y],\n",
    "            \"max_x\": [combined_max_x],\n",
    "            \"max_y\": [combined_max_y],\n",
    "            \"width\": [combined_max_x - combined_min_x],\n",
    "            \"height\": [combined_max_y - combined_min_y],\n",
    "            \"area\": [combined_polygon.area],\n",
    "        },\n",
    "        crs=crs,\n",
    "    )\n",
    "\n",
    "    return pc_bbox, geo_bbox, combined_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "073d5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bounding box from point cloud...\n",
      "Point cloud bounding box:\n",
      "                                            geometry     min_x       min_y  \\\n",
      "0  POLYGON ((125399.999 456300.001, 125399.999 45...  125300.0  456300.001   \n",
      "\n",
      "        max_x       max_y   width  height         area  n_points  \n",
      "0  125399.999  456399.999  99.999  99.998  9999.700002    206231  \n",
      "\n",
      "Bounding box coordinates: [np.float64(125300.0), np.float64(456300.001), np.float64(125399.999), np.float64(456399.999)]\n"
     ]
    }
   ],
   "source": [
    "# Test de bounding box functies\n",
    "print(\"Creating bounding box from point cloud...\")\n",
    "\n",
    "# Krijg bounding box van de point cloud als GeoDataFrame\n",
    "pc_bbox_gdf = pointcloud_to_bbox_gdf(lasdata, crs=\"EPSG:28992\")\n",
    "\n",
    "print(\"Point cloud bounding box:\")\n",
    "print(pc_bbox_gdf)\n",
    "\n",
    "# Krijg ook de simpele coördinaten lijst\n",
    "bbox_coords = pointcloud_to_bbox_coords(lasdata)\n",
    "print(f\"\\nBounding box coordinates: {bbox_coords}\")\n",
    "\n",
    "# Vergelijk met BGT data bounding box\n",
    "if \"geodata\" in locals():\n",
    "    print(\"\\nComparing bounding boxes...\")\n",
    "    pc_bbox, geo_bbox, combined_bbox = compare_bboxes(lasdata, geodata_dict[\"pand\"], \"EPSG:28992\")\n",
    "\n",
    "    print(\"\\nPoint cloud bbox:\")\n",
    "    print(f\"  Area: {pc_bbox.iloc[0]['area']:.2f} m²\")\n",
    "    print(f\"  Dimensions: {pc_bbox.iloc[0]['width']:.1f} x {pc_bbox.iloc[0]['height']:.1f} m\")\n",
    "\n",
    "    print(\"\\nBGT data bbox:\")\n",
    "    print(f\"  Area: {geo_bbox.iloc[0]['area']:.2f} m²\")\n",
    "    print(f\"  Dimensions: {geo_bbox.iloc[0]['width']:.1f} x {geo_bbox.iloc[0]['height']:.1f} m\")\n",
    "\n",
    "    print(\"\\nCombined bbox:\")\n",
    "    print(f\"  Area: {combined_bbox.iloc[0]['area']:.2f} m²\")\n",
    "    print(\n",
    "        f\"  Dimensions: {combined_bbox.iloc[0]['width']:.1f} x {combined_bbox.iloc[0]['height']:.1f} m\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0d528",
   "metadata": {},
   "source": [
    "## Stap 3: Visuele controle van de overlap\n",
    "\n",
    "Laten we ook even visueel inspecteren of de data inderdaad overlapt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ca9cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benodigde functies\n",
    "def plot_bounding_boxes(bbox_coords_list, labels=None, colors=None, title=\"Bounding Boxes\"):\n",
    "    \"\"\"\n",
    "    Plot multiple bounding boxes using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        bbox_coords_list: List of bounding box coordinates, each as [min_x, min_y, max_x, max_y]\n",
    "        labels: List of labels for each bounding box\n",
    "        colors: List of colors for each bounding box\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    # Default colors and labels if not provided\n",
    "    if colors is None:\n",
    "        colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "    if labels is None:\n",
    "        labels = [f\"Bbox {i + 1}\" for i in range(len(bbox_coords_list))]\n",
    "\n",
    "    # Plot each bounding box\n",
    "    for i, bbox in enumerate(bbox_coords_list):\n",
    "        min_x, min_y, max_x, max_y = bbox\n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "\n",
    "        # Create rectangle patch\n",
    "        rect = patches.Rectangle(\n",
    "            (min_x, min_y),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor=colors[i % len(colors)],\n",
    "            facecolor=\"none\",\n",
    "            label=labels[i],\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add text with coordinates\n",
    "        ax.text(\n",
    "            min_x,\n",
    "            max_y + height * 0.02,\n",
    "            f\"{labels[i]}\\n{width:.1f} x {height:.1f} m\",\n",
    "            fontsize=10,\n",
    "            color=colors[i % len(colors)],\n",
    "        )\n",
    "\n",
    "    # Set equal aspect ratio and adjust view\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Calculate overall bounds for nice view\n",
    "    all_coords = np.array(bbox_coords_list)\n",
    "    overall_min_x = np.min(all_coords[:, 0])\n",
    "    overall_min_y = np.min(all_coords[:, 1])\n",
    "    overall_max_x = np.max(all_coords[:, 2])\n",
    "    overall_max_y = np.max(all_coords[:, 3])\n",
    "\n",
    "    # Add some padding\n",
    "    padding_x = (overall_max_x - overall_min_x) * 0.1\n",
    "    padding_y = (overall_max_y - overall_min_y) * 0.1\n",
    "\n",
    "    ax.set_xlim(overall_min_x - padding_x, overall_max_x + padding_x)\n",
    "    ax.set_ylim(overall_min_y - padding_y, overall_max_y + padding_y)\n",
    "\n",
    "    # Labels and grid\n",
    "    ax.set_xlabel(\"X (m)\")\n",
    "    ax.set_ylabel(\"Y (m)\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3557432a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pc_bbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plot_bounding_boxes(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     [\u001b[43mpc_bbox\u001b[49m.bounds.values.tolist()[\u001b[32m0\u001b[39m], geo_bbox.bounds.values.tolist()[\u001b[32m0\u001b[39m]],\n\u001b[32m      3\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[33mpointcloud\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgeodata\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mBounding Box Comparison\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'pc_bbox' is not defined"
     ]
    }
   ],
   "source": [
    "plot_bounding_boxes(\n",
    "    [pc_bbox.bounds.values.tolist()[0], geo_bbox.bounds.values.tolist()[0]],\n",
    "    [\"pointcloud\", \"geodata\"],\n",
    "    [\"red\", \"blue\"],\n",
    "    title=\"Bounding Box Comparison\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f6b11",
   "metadata": {},
   "source": [
    "## Stap 4: Pointcloud classificatie van een pointcloud tile met BGT data\n",
    "\n",
    "In deze laatste stap geven we de puntenwolk de classificatie van de BGT vlakken waarmee ze overlappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "571c787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geodata_with_index(filepath: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load each layer of the geodata as separate GeoDataFrames.\n",
    "    Returns a dictionary with layer names as keys and GeoDataFrames as values.\n",
    "    \"\"\"\n",
    "\n",
    "    layers = gpd.list_layers(output_folder / bgt_name).name.to_list()\n",
    "    geodata = {}\n",
    "    for layer in layers:\n",
    "        geodata[layer] = gpd.read_file(filepath, layer=layer)\n",
    "\n",
    "    return geodata\n",
    "\n",
    "\n",
    "def prepare_pointcloud_geoms(points: np.ndarray):\n",
    "    \"\"\"\n",
    "    Prepares the pointcloud\n",
    "    \"\"\"\n",
    "    # Extract X,Y coordinates (ignore Z if present)\n",
    "    xy_points = points[:, :2]\n",
    "\n",
    "    # Create Point geometries from coordinates\n",
    "    point_geoms = [Point(x, y) for x, y in xy_points]\n",
    "\n",
    "    return point_geoms\n",
    "\n",
    "\n",
    "def points_in_polygons(\n",
    "    points: np.ndarray,\n",
    "    point_geoms: list[Point],\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    classification: int = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Find which polygon each point falls into.\n",
    "\n",
    "    Args:\n",
    "        points: numpy array with shape (n_points, 2) or (n_points, 3) - X,Y coordinates (Z ignored if present)\n",
    "        gdf: GeoDataFrame with polygon geometries\n",
    "\n",
    "    Returns:\n",
    "        numpy array with shape (n_points,) containing the index of the polygon each point falls into.\n",
    "        Returns -1 if point doesn't fall in any polygon.\n",
    "    \"\"\"\n",
    "    # Create spatial index for fast lookup\n",
    "    tree = STRtree(gdf.geometry.values)\n",
    "\n",
    "    # For each point, find which polygon it falls into\n",
    "    for i, point_geom in enumerate(point_geoms):\n",
    "        # Query spatial index for potential matches\n",
    "        possible_matches_idx = list(tree.query(point_geom))\n",
    "\n",
    "        # Check actual containment for potential matches\n",
    "        for idx in possible_matches_idx:\n",
    "            if gdf.geometry.iloc[idx].contains(point_geom):\n",
    "                if classification is None:\n",
    "                    points[i, 3] = idx\n",
    "                else:\n",
    "                    points[i, 3] = classification\n",
    "                break  # Found the polygon, move to next point\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afdd786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasdata_with_classification = np.zeros((len(lasdata), 4))\n",
    "lasdata_with_classification[:, :3] = lasdata  # Copy X, Y, Z\n",
    "lasdata_with_classification[:, 3] = -1\n",
    "\n",
    "# Prepare shapely point geometries, so we don't do this every time we call the function\n",
    "lasdata_geoms = prepare_pointcloud_geoms(lasdata_with_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924281b",
   "metadata": {},
   "source": [
    "Voordat je het codeblok hieronder draait, open naast je code een CPU monitor, zoals:\n",
    "\n",
    "1) Windows: task manager --> CPU --> rechter muisklik op de grote grafiek --> logical processors\n",
    "2) Linux: htop commando\n",
    "\n",
    "__Vraag: Run nu de code hieronder. Wat zie je in je CPU cores gebeuren?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dd62e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vind voor elk punt in welk BGT polygoon het valt\n",
    "for classification, data in enumerate(geodata_dict.values()):\n",
    "    lasdata_with_classification = points_in_polygons(\n",
    "        points=lasdata_with_classification,\n",
    "        point_geoms=lasdata_geoms,\n",
    "        gdf=data,\n",
    "        classification=classification + 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9050fe",
   "metadata": {},
   "source": [
    "__Vraag: Kijk nu naar hoe lang deze ene operatie heeft gekost. Hoe lang denk je dat dit zou duren voor alle 100 pointcloud tile?__    \n",
    "[antwoord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3df02f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classifications found: [ 1.  2.  6. 10.]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Welke classes heeft hij gevonden?\n",
    "(f\"Classifications found: {np.unique(lasdata_with_classification[:, 3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "655317bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_classified = to_las(\n",
    "    points=lasdata_with_classification[:, 0:3],\n",
    "    colors=None,\n",
    "    extra_dim={\"bgt_classification\": lasdata_with_classification[:, 3].astype(\"uint32\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bbef550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing classified LAS to /home/sjoerd/projects/geonovum_workshop/data/utrecht_subset/output/AHN5_C_125000_456000_3_3_bgt_classification.las\n"
     ]
    }
   ],
   "source": [
    "las_path = output_folder / Path(Path(lasfile_path).stem + \"_bgt_classification.las\")\n",
    "print(f\"Writing classified LAS to {Path(os.getcwd()) / las_path}\")\n",
    "las_classified.write(las_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f19128",
   "metadata": {},
   "source": [
    "## Stap 5: Pointcloud classificatie van alle pointcloud tiles met BGT data\n",
    "\n",
    "In deze laatste stap gaan we elke tile van de puntenwolk classificeren. Alleen met 1 groot verschil: \n",
    "We voeren de classificatie multi-threaded uit!\n",
    "Python is namelijk standaard single-thread. Dit betekent dat het voor al zijn werk slechts 1 CPU core gebruikt. \n",
    "Tegenwoordig hebben laptops echter minimaal 4 cores of meer.\n",
    "We laten dus 3 cores lekker luieren terwijl eentje keihard werkt!\n",
    "\n",
    "Wat als we alle cores een aparte taak geven om uit te voeren, zoals het classificeren van een tile? Vervolgens halen we alle classificaties van de cores op en slaan we die op.\n",
    "Multi-threaded code draaien is in deze workshop de analogie voor cloud computing: In plaats van dat je alles lokaal op 1 machine draait \n",
    "(je single-threaded core), \n",
    "kunnen we een cluster aan machines aanroepen en elk een stukje van de taak geven (multi-threaded workloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1524e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiy_lasfiles(lasfile_path: str, geodata_dict: dict, output_folder: Path) -> None:\n",
    "    \"\"\"\n",
    "    function for multiprocessing.\n",
    "    \"\"\"\n",
    "\n",
    "    lasdata = lasdata_loader(lasfile_path, single_array=True)\n",
    "\n",
    "    lasdata_with_classification = np.zeros((len(lasdata), 4))\n",
    "    lasdata_with_classification[:, :3] = lasdata  # Copy X, Y, Z\n",
    "    lasdata_with_classification[:, 3] = -1\n",
    "\n",
    "    # Prepare shapely point geometries, so we don't do this every time we call the function\n",
    "    lasdata_geoms = prepare_pointcloud_geoms(lasdata_with_classification)\n",
    "\n",
    "    # Vind voor elk punt in welk BGT polygoon het valt\n",
    "    for classification, data in enumerate(geodata_dict.values()):\n",
    "        lasdata_with_classification = points_in_polygons(\n",
    "            points=lasdata_with_classification,\n",
    "            point_geoms=lasdata_geoms,\n",
    "            gdf=data,\n",
    "            classification=classification + 1,\n",
    "        )\n",
    "\n",
    "    las_classified = to_las(\n",
    "        points=lasdata_with_classification[:, 0:3],\n",
    "        colors=None,\n",
    "        extra_dim={\"bgt_classification\": lasdata_with_classification[:, 3].astype(\"uint32\")},\n",
    "    )\n",
    "\n",
    "    print(f\"Saving output of {str(Path(lasfile_path).stem)} to las file...\")\n",
    "    las_path = output_folder / Path(Path(lasfile_path).stem + \"_bgt_classification.las\")\n",
    "    print(f\"Writing classified LAS to {Path(os.getcwd()) / las_path}\")\n",
    "    las_classified.write(las_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60ac10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal beschikbare cores: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Aantal beschikbare cores:\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83e29627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle 100 lasfiles verwerken is erg veel. Kies hieronder een subset, of maak je eigen lijst met gekozen lasfiles\n",
    "# De files worden in dezelfde output folder opgeslagen\n",
    "\n",
    "lasfiles_subset = lasfiles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "197f0ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 cores to process 10 files\n",
      "Saving output of AHN5_C_125000_456000_5_1 to las file...\n",
      "Writing classified LAS to /home/sjoerd/projects/geonovum_workshop/data/utrecht_subset/output/AHN5_C_125000_456000_5_1_bgt_classification.las\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cores to process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lasfiles_subset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=num_cores) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# This will distribute the files across all cores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify_single_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlasfiles_subset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll files processed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def classify_single_file(lasfile_path):\n",
    "    \"\"\"Wrapper function for pool processing\"\"\"\n",
    "    return classifiy_lasfiles(lasfile_path, geodata_dict, output_folder)\n",
    "\n",
    "\n",
    "# We use one core less than total to avoid overloading the system\n",
    "num_cores = min(multiprocessing.cpu_count() - 1, len(lasfiles_subset))\n",
    "print(f\"Using {num_cores} cores to process {len(lasfiles_subset)} files\")\n",
    "\n",
    "with Pool(processes=num_cores) as pool:\n",
    "    # This will distribute the files across all cores\n",
    "    pool.map(classify_single_file, lasfiles_subset)\n",
    "\n",
    "print(\"All files processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebb52a",
   "metadata": {},
   "source": [
    "__Vraag: Hoe lang heeft het verwerken van de files geduurd? Is dit wat je had verwacht?__    \n",
    "[antwoord]\n",
    "\n",
    "__Vraag: Als je kijkt naar de volgorde van files van je subset komt deze niet overeen met de volgorde van de output. Waarom?__\n",
    "[antwoord]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geonovum-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
